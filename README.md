## Models for Nature Language Inference (NLI).

We try to reproduct some classical models in literal papers for Nature Language Inferece, and show performance on Stanford Natural Language Inference data set ([SNLI](https://nlp.stanford.edu/projects/snli/)). 

## Models
- decompose: A Decomposable Attention Model for Natural Language Inference, [paper](http://www.aclweb.org/anthology/D16-1244)
- To be continued ...

## Environment
- TensorFlow 1.3 or higher
- Python 3.5
- Numpy
- Sklearn

## Data preparation
To be continued ...


Model          | Acc reported in papers  | Our Acc
------------   | -------------           | -------------
decompose      | 86.3%                   | 86.19%
